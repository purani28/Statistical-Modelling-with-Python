{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.069\n",
      "Model:                            OLS   Adj. R-squared:                 -0.138\n",
      "Method:                 Least Squares   F-statistic:                    0.3338\n",
      "Date:                Mon, 18 Nov 2024   Prob (F-statistic):              0.725\n",
      "Time:                        18:02:53   Log-Likelihood:                -40.435\n",
      "No. Observations:                  12   AIC:                             86.87\n",
      "Df Residuals:                       9   BIC:                             88.33\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -9.9931     21.340     -0.468      0.651     -58.267      38.281\n",
      "x1            -0.0250      0.087     -0.288      0.780      -0.221       0.171\n",
      "x2             4.4988      5.507      0.817      0.435      -7.959      16.957\n",
      "==============================================================================\n",
      "Omnibus:                        7.523   Durbin-Watson:                   0.773\n",
      "Prob(Omnibus):                  0.023   Jarque-Bera (JB):                3.422\n",
      "Skew:                           1.135   Prob(JB):                        0.181\n",
      "Kurtosis:                       4.301   Cond. No.                         603.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Conversion degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Differences in coordinates\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    # Conversion from km to m\n",
    "    distance = R * c * 1000  \n",
    "    return distance\n",
    "\n",
    "\n",
    "url = \"http://api.citybik.es/v2/networks/velib\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    stations = data['network']['stations']\n",
    "    \n",
    "    station_details = []\n",
    "    for station in stations:\n",
    "        lat = station['latitude']\n",
    "        lon = station['longitude']\n",
    "        free_bikes = station['free_bikes']\n",
    "        \n",
    "        station_details.append({\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'free_bikes': free_bikes\n",
    "        })\n",
    "    \n",
    "    df_bikes = pd.DataFrame(station_details)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "yelp_api_key = os.getenv('YELP_API_KEY')\n",
    "lat, lon = 48.879359419425, 2.3665961623192\n",
    "yelp_url = f\"https://api.yelp.com/v3/businesses/search?latitude={lat}&longitude={lon}&radius=1000\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {yelp_api_key}',\n",
    "    'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.get(yelp_url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    places_list = []\n",
    "    if 'businesses' in data:\n",
    "        for place in data['businesses']:\n",
    "            name = place.get('name', 'No name')\n",
    "            location = place.get('location', {})\n",
    "            address = \", \".join([str(location.get('address1', 'No address provided')),\n",
    "                                 str(location.get('address2', '')),\n",
    "                                 str(location.get('address3', ''))]).strip(', ')\n",
    "            city = location.get('city', 'No city provided')\n",
    "            country = location.get('country', 'No country provided')\n",
    "            rating = place.get('rating', 'No rating available')\n",
    "            coordinates = place.get('coordinates', {})\n",
    "            lat = coordinates.get('latitude')\n",
    "            lon = coordinates.get('longitude')\n",
    "            \n",
    "            if lat is not None and lon is not None:\n",
    "                places_list.append({\n",
    "                    'Name': name,\n",
    "                    'Address': address,\n",
    "                    'City': city,\n",
    "                    'Country': country,\n",
    "                    'Rating': rating,\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lon\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Missing latitude/longitude for place: {name}\")\n",
    "    \n",
    "    df_places = pd.DataFrame(places_list)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "\n",
    "# Drop rows with missing latitude or longitude\n",
    "df_bikes.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "df_places.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "# Maximum distance threshold = 100 meters\n",
    "max_distance = 100  \n",
    "\n",
    "merged_data = []\n",
    "\n",
    "for bike_index in range(len(df_bikes)):\n",
    "    bike_lat = df_bikes.iloc[bike_index]['latitude']\n",
    "    bike_lon = df_bikes.iloc[bike_index]['longitude']\n",
    "    free_bikes = df_bikes.iloc[bike_index]['free_bikes']\n",
    "    \n",
    "    for place_index in range(len(df_places)):\n",
    "        place_lat = df_places.iloc[place_index]['latitude']\n",
    "        place_lon = df_places.iloc[place_index]['longitude']\n",
    "        \n",
    "        #Distance between the bike station and the place\n",
    "        distance = haversine(bike_lat, bike_lon, place_lat, place_lon)\n",
    "        \n",
    "        # Check for distance is <= 100m \n",
    "        if distance <= max_distance:\n",
    "            merged_data.append({\n",
    "                'latitude': bike_lat,\n",
    "                'longitude': bike_lon,\n",
    "                'free_bikes': free_bikes,\n",
    "                'Name': df_places.iloc[place_index]['Name'],\n",
    "                'Address': df_places.iloc[place_index]['Address'],\n",
    "                'City': df_places.iloc[place_index]['City'],\n",
    "                'Country': df_places.iloc[place_index]['Country'],\n",
    "                'Rating': df_places.iloc[place_index]['Rating'],\n",
    "                'Distance (m)': distance\n",
    "            })\n",
    "\n",
    "df_merged = pd.DataFrame(merged_data)\n",
    "\n",
    "\n",
    "X = df_merged[['Distance (m)', 'Rating']].values\n",
    "y = df_merged['free_bikes'].values\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)  \n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide model output and an interpretation of the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low R-squaerd value (6.9%) suggests that the model is not explaining much of the variability in the number of free bikes. Neither distance nor rating are statistically significant predictors of the number of free bikes, as indicated by their high p-values. More data is needed to help improve the model's performance and significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you turn the regression model into a classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   free_bikes free_bikes_category\n",
      "0        14.0              Medium\n",
      "1        26.0                High\n",
      "2         9.0              Medium\n",
      "3        11.0              Medium\n",
      "4         6.0              Medium\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: nan\n",
      "         Iterations: 35\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   12\n",
      "Model:                        MNLogit   Df Residuals:                        6\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 18 Nov 2024   Pseudo R-squ.:                     nan\n",
      "Time:                        18:05:55   Log-Likelihood:                    nan\n",
      "converged:                      False   LL-Null:                       -11.021\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "==============================================================================\n",
      "       y=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -9.3736      7.564     -1.239      0.215     -24.198       5.451\n",
      "x1             0.0415      0.032      1.317      0.188      -0.020       0.103\n",
      "x2             1.7288      1.797      0.962      0.336      -1.793       5.251\n",
      "------------------------------------------------------------------------------\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        196.3157        nan        nan        nan         nan         nan\n",
      "x1           -19.1740        nan        nan        nan         nan         nan\n",
      "x2            13.1924        nan        nan        nan         nan         nan\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:3059: RuntimeWarning: divide by zero encountered in log\n",
      "  logprob = np.log(self.cdf(np.dot(self.exog,params)))\n",
      "c:\\Users\\krish\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:3060: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sum(d * logprob)\n",
      "c:\\Users\\krish\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\krish\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:5475: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse = np.sqrt(np.diag(self.cov_params()))\n"
     ]
    }
   ],
   "source": [
    "# Categorize bikes to Low, Medium, High\n",
    "bins = [0, 5, 15, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "df_merged['free_bikes_category'] = pd.cut(df_merged['free_bikes'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Convert the 'free_bikes_category' into a categorical variable\n",
    "df_merged['free_bikes_category'] = pd.Categorical(df_merged['free_bikes_category'])\n",
    "\n",
    "X = df_merged[['Distance (m)', 'Rating']].values  \n",
    "y = df_merged['free_bikes_category'].cat.codes  \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.MNLogit(y, X).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
